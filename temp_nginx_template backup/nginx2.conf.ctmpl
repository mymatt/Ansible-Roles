{{ name_web_list }}
{{ name_web_list|replace("[", "")|replace("]", "")|replace("\"", "") }}
{% set web_list = name_web_list|replace("[", "")|replace("]", "")|replace("\"", "") %}
{{ web_list }}
{% set list1 = web_list.split(',') %}
index1: {{ list1[0] }} index2 {{ list1[1] }}

worker_processes auto; # auto equals the number of cores (one process per core)
# Max Connections = worker_processes x worker_connections
# worker_connections based on ulimit (check ulimit)
events {
  worker_connections 1024;
}

error_log /var/log/nginx/error.log;




  http {

    include mime.types;

    # log_format test '"$http_referer" "$http_host" "$sent_http_host" "$http_server_name" "$sent_http_server_name" ';
    log_format test
        '"$request"'
        '"$http_referer" "$host" '
        '"$http_host" "$server_name" '
        '"$remote_user" "$upstream_addr" '
        '"$upstream_http_server" "$upstream_http_location" '
        '"$upstream_addr$uri" "$remote_addr" '
        '"$http_user_agent" "$http_x_forwarded_for" ';

    access_log /var/log/nginx/access.log test;

    #  Buffer size for POST submissions
    client_body_buffer_size 10K; #specific to nature of requests received
    client_max_body_size 8m; #prevents large request slowing down server

    # Buffer size for Headers
    client_header_buffer_size 1k;

    # Max time to receive client headers/body in ms
    client_body_timeout 12; #time between consecutive read operations to buffer
    client_header_timeout 12;

    # Max time to keep a connection open for in case more data is on the way, reduces the time to open another connection
    # important not to keep connection open to long to avoid using up max connections
    keepalive_timeout 30;

    # Max time for the client accept/receive a response
    send_timeout 10;

    # for sites with large amount of static resources
    # Skip buffering for static files (image sent from disk)
    sendfile on; # slight increase in performance

    # Optimise sendfile packets
    tcp_nopush on; #allows tcp to optimise
    # profile_web_active

    upstream main {
      {% for item in name_web_list %}
        {{ '{{' }}if ne {{ '(' }}keyOrDefault {{'"'}}{{ kv_path_web }}/{{ weight_web_list[loop.index0] }}{{'"'}} {{'"'}}0{{'"'}}{{ ')' }} {{'"'}}0{{'"'}} {{ '}}' }}
               server {{ item }}.tf.local weight={{ '{{' }}keyOrDefault {{'"'}}{{ kv_path_web }}/{{ weight_web_list[loop.index0] }}{{'"'}} {{'"'}}1{{'"'}} {{ '}}' }};
          {{ '{{' }}end{{ '}}' }}
      {% endfor %}
    }
    {% for item in location_web_list %}
      upstream {{ item }} {
        server {{ name_web_list[loop.index0] }}.tf.local;
      }
    {% endfor %}



    server{

      listen 80; #443 https
      server_name {{ nginx_server_ip }};

      root {{ site_location }};

      location = / {
      {{ '{{' }}if eq {{ '(' }}keyOrDefault {{'"'}}{{ kv_path_web }}/{{ start_web }}{{'"'}} {{'"'}}0{{'"'}}{{ ')' }} {{'"'}}0{{'"'}} {{ '}}' }}
        return 200 "Hello from NGINX Proxy\n";
      {{ '{{' }}else if eq {{ '(' }}keyOrDefault {{'"'}}{{ kv_path_web }}/{{ start_web }}{{'"'}} {{'"'}}0{{'"'}}{{ ')' }} {{'"'}}1{{'"'}} {{ '}}' }}
        proxy_pass http://main;
        proxy_set_header X-Forwarded-Host $http_host;
        # proxy_set_header Host $http_host;
        # proxy_set_header X-Real-IP $remote_addr;
        # proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        # proxy_set_header X-Forwarded-Proto $scheme;
      {{ '{{' }}end{{ '}}' }}
      }
      {% for item in location_web_list %}
      location = /{{ item }} {
        proxy_pass http://{{ item }};
        proxy_set_header Host {{ name_web_list[loop.index0] }}.tf.local;
      }
      {% endfor %}

    }
  }
